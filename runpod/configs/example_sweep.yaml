# F5-TTS Hyperparameter Sweep Configuration
#
# Usage:
#   python sweep.py launch --config configs/example_sweep.yaml
#   python sweep.py launch --config configs/example_sweep.yaml --dry-run

# RunPod infrastructure settings
runpod:
  image: "echoai/f5tts-train:v1"          # Docker Hub image (build and push first)
  gpu_type: "NVIDIA GeForce RTX 3090"      # GPU type ID
  cloud_type: "COMMUNITY"                   # COMMUNITY (cheap) or SECURE (reliable)
  network_volume_id: "REPLACE_ME"           # From RunPod console after creating volume
  data_center_id: null                      # null = any DC with the volume
  container_disk_gb: 20                     # Container-local scratch disk
  min_memory_gb: 24                         # Minimum system RAM

  # Cost estimation (for preview only, not enforced)
  cost_per_hour: 0.22
  estimated_hours_per_run: 0.4              # ~24 min per 8-epoch run on RTX 3090

# Parameters to sweep (grid search: all combinations)
# 4 LRs Ã— 2 batch sizes = 8 total runs
sweep:
  LEARNING_RATE: [5e-6, 1e-5, 5e-5, 1e-4]
  BATCH_SIZE: [4000, 5000]

# Fixed parameters (same for every run)
fixed:
  EPOCHS: 8
  WARMUP_UPDATES: 50
  SAVE_PER_UPDATES: 500
  KEEP_LAST_N: 3
  LAST_PER_UPDATES: 200
  MAX_SAMPLES: 32
  GRAD_ACCUM: 1
  MAX_GRAD_NORM: 1.0
  CHECKPOINT_ACTIVATIONS: "False"
  DATASET_NAME: kokoro_libri
  CONFIG_NAME: F5TTS_RunPod_Base
